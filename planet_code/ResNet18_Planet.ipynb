{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "sE_ECMJf2G0J",
        "-7i0TYZUwLD2",
        "Pswof8zV5PnZ",
        "zbUyOOhQdX3m"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Set-up"
      ],
      "metadata": {
        "id": "sE_ECMJf2G0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted from [this Kaggle notebook](https://www.kaggle.com/code/vincentmaladiere/pytorch-resnet18-0-93) and from Indu Panigrahi's and Carlos Jimenez's Princeton AI4ALL sessions."
      ],
      "metadata": {
        "id": "ghySuMc-pFHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install ftfy regex tqdm"
      ],
      "metadata": {
        "id": "3aY_8jKkWIwX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1317bcb7-d6f3-432a-a52b-4e91cf74192b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m509.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.12)\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1rD8NzCsUJbuUyH-b6zDylp8m4ZVPY9lH -O amazon-dataset-split-all.tar.gz\n",
        "!gdown https://drive.google.com/uc?id=1Qpdhlky4uaMBj4kvsKnFWD1nAsEaI5UH -O train_classes.csv\n",
        "!tar -xzf amazon-dataset-split-all.tar.gz && rm -f amazon-dataset-split-all.tar.gz"
      ],
      "metadata": {
        "id": "hZ4RYANyUY-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51cc61cf-d67a-4f4f-c3d5-45f130386f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rD8NzCsUJbuUyH-b6zDylp8m4ZVPY9lH\n",
            "To: /content/amazon-dataset-split-all.tar.gz\n",
            "100% 630M/630M [00:05<00:00, 125MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Qpdhlky4uaMBj4kvsKnFWD1nAsEaI5UH\n",
            "To: /content/train_classes.csv\n",
            "100% 1.43M/1.43M [00:00<00:00, 55.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from time import time\n",
        "import pandas as pd\n",
        "import numpy as np # for numerical operations, super useful for dealing with arrays/matrices\n",
        "from tqdm.notebook import tqdm\n",
        "import pickle # for storing information into pickle files\n",
        "\n",
        "# for visualization\n",
        "from plotly import graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# for the scores and confusion matrices\n",
        "from sklearn.metrics import fbeta_score, confusion_matrix\n",
        "\n",
        "# for visualization\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "\n",
        "# PyTorch imports: useful for anything to do with our model\n",
        "# (i.e., the model itself, loading the data into the model, etc,)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms as T, models\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "!pip install -q torchsummary --user\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "OMSS4YTBuMtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "mjiGdRB3eN2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rainforest Data"
      ],
      "metadata": {
        "id": "-7i0TYZUwLD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# checking how much training and validation data we have\n",
        "train_paths = [\"amazon-dataset-split-all/train\", ]\n",
        "val_paths = [\"amazon-dataset-split-all/validation\", ]\n",
        "num_train = sum([len(os.listdir(path)) for path in train_paths])\n",
        "num_val = sum([len(os.listdir(path)) for path in val_paths])\n",
        "print(\n",
        "    f\"train files: {num_train}, \"\n",
        "    f\"validation files: {num_val}\"\n",
        ")"
      ],
      "metadata": {
        "id": "Pdh15tMVn19T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415a8298-9d48-4efd-8860-bc87ba4eebad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train files: 32370, validation files: 8109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# taking a quick look at our training data\n",
        "path_class = os.path.join(\"train_classes.csv\") # original is train_classes.csv\n",
        "df_class = pd.read_csv(path_class)\n",
        "df_class = df_class\n",
        "df_class.head()\n",
        "df_class[\"list_tags\"] = df_class.tags.str.split(\" \")"
      ],
      "metadata": {
        "id": "Mw5a3nlhn4Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# another helper function for loading data information\n",
        "def load_split(paths, df_class):\n",
        "    if isinstance(paths, str):\n",
        "        paths = [paths]\n",
        "    elif not isinstance(paths, (list, tuple, set)):\n",
        "        raise ValueError('Expected type in {list, tuple, set, str} but got ' + str(type(paths)))\n",
        "    image_names = list()\n",
        "    for path in paths:\n",
        "        image_names += list(map(lambda x: x.split('.', 1)[0], os.listdir(path)))\n",
        "    return df_class[df_class.image_name.map(lambda x: x in image_names)].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "K2wT-_AOtfXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the possible labels for our dataset\n",
        "LABEL_IDXS = {\n",
        "    'agriculture': 0,\n",
        "    'artisinal_mine': 1,\n",
        "    'bare_ground': 2,\n",
        "    'blooming': 3,\n",
        "    'blow_down': 4,\n",
        "    'clear': 5,\n",
        "    'cloudy': 6,\n",
        "    'conventional_mine': 7,\n",
        "    'cultivation': 8,\n",
        "    'habitation': 9,\n",
        "    'haze': 10,\n",
        "    'partly_cloudy': 11,\n",
        "    'primary': 12,\n",
        "    'road': 13,\n",
        "    'selective_logging': 14,\n",
        "    'slash_burn': 15,\n",
        "    'water': 16,\n",
        "}\n",
        "INVERSE_LABEL_IDXS = {v: k for k, v in LABEL_IDXS.items()}\n",
        "\n",
        "# converts the parameter tag_list (list of words, subset of the keys in LABEL_IDXS) to a one-hot encoding\n",
        "def transform_targets(tag_list):\n",
        "    targets = np.zeros(len(LABEL_IDXS), dtype=np.int8)\n",
        "    mask = [LABEL_IDXS[tag] for tag in tag_list]\n",
        "    targets[mask] = 1\n",
        "    # returns list of ones and zeros\n",
        "    # (e.g. tag_list = ['primary', 'haze'] -> [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
        "    return targets.tolist()\n",
        "\n",
        "# converts the parameter targets (one-hot encoding) back into a list of tags (subset of words from LABEL_IDXS)\n",
        "def inverse_transform_targets(targets):\n",
        "    idxs = [idx for idx, target in enumerate(targets) if target]\n",
        "    tag_list = [INVERSE_LABEL_IDXS[ix] for ix in idxs]\n",
        "    return list(sorted(tag_list))"
      ],
      "metadata": {
        "id": "Fi8hIGpbtolI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "class AmazonDataset(Dataset):\n",
        "    # basically defines what information we store for a dataset\n",
        "    def __init__(\n",
        "        self,\n",
        "        df,\n",
        "        transform,\n",
        "        paths,\n",
        "        is_train=True,\n",
        "        idx_tta=None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.ohe_tags = list(map(transform_targets, self.df.list_tags.values))\n",
        "        self.transform = transform\n",
        "        if isinstance(paths, str):\n",
        "            self.paths = [paths]\n",
        "        elif isinstance(paths, (list, tuple)):\n",
        "            self.paths = paths\n",
        "        else:\n",
        "            raise ValueError('expected path to be a string or list or tuple')\n",
        "        self.is_train = is_train\n",
        "        if not is_train:\n",
        "            if not idx_tta in list(range(6)):\n",
        "                raise ValueError(\n",
        "                    f\"In test mode, 'idx_tta' must be an int belonging to [0, 5], got: {repr(idx_tta)}\"\n",
        "                )\n",
        "            self.idx_tta = idx_tta\n",
        "\n",
        "    # returns how many examples are in the data\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    # get the example corresponding to the parameter idx from the dataset\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.df.iloc[idx].image_name + \".jpg\"\n",
        "        files = list()\n",
        "        for path in self.paths:\n",
        "            file_path = os.path.join(path, filename)\n",
        "            if os.path.isfile(file_path):\n",
        "                files.append(file_path)\n",
        "        if len(files) == 0:\n",
        "            raise FileNotFoundError(filename + ' not found in ' + ' '.join(self.paths))\n",
        "        elif len(files) > 1:\n",
        "            raise ValueError(f'Found {len(files)} values for {filename} as {files}')\n",
        "        else:\n",
        "            file_path = files[0]\n",
        "        img = cv2.imread(file_path)\n",
        "        if img is None:\n",
        "            raise ValueError('Problem reading image from %s' % file_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        label = self.ohe_tags[idx]\n",
        "        return img, label\n",
        "\n",
        "    # returns images and labels in a batch with augmentations applied\n",
        "    def collate_fn(self, batch):\n",
        "        imgs, labels = [], []\n",
        "        for (img, label) in batch:\n",
        "            # img = Image.fromarray(img)\n",
        "            img = self.custom_augment(img)\n",
        "            img = torch.tensor(img)\n",
        "            img = img.permute(2, 0, 1)\n",
        "            img = self.transform(img)\n",
        "            imgs.append(img[None])\n",
        "            labels.append(label)\n",
        "        imgs = torch.cat(imgs).float().to(device)\n",
        "        labels = torch.tensor(labels).float().to(device)\n",
        "        return imgs, labels\n",
        "\n",
        "    # loads and displays the example corresponding to the parameter idx\n",
        "    def load_img(self, idx, ax=None):\n",
        "        img, ohe_label = self[idx]\n",
        "        label = self.df.iloc[idx].tags\n",
        "        title = f\"{label} - {ohe_label}\"\n",
        "        if ax is None:\n",
        "            plt.imshow(img)\n",
        "            plt.title(title)\n",
        "        else:\n",
        "            ax.imshow(img)\n",
        "            ax.set_title(title)\n",
        "\n",
        "    # applies data augmentations to the parameter img, not used\n",
        "    def custom_augment(self, img):\n",
        "        \"\"\"\n",
        "        If we want data augmentations\n",
        "        \"\"\"\n",
        "        return img"
      ],
      "metadata": {
        "id": "1174HZ1gsEUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transforms():\n",
        "    transform_train = T.Compose([\n",
        "      T.ToPILImage(),\n",
        "      T.Resize(224),\n",
        "      T.ToTensor(),\n",
        "      T.Normalize(\n",
        "          mean=[0.485, 0.456, 0.406],  # Set by previously known values\n",
        "          std=[0.229, 0.224, 0.225],   # Set by previously known values\n",
        "      )\n",
        "    ])\n",
        "    transform_val = T.Compose([\n",
        "      T.ToPILImage(),\n",
        "      T.Resize(224),\n",
        "      T.ToTensor(),\n",
        "      T.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],  # Set by previously known values\n",
        "        std=[0.229, 0.224, 0.225],   # Set by previously known values\n",
        "      )\n",
        "    ])\n",
        "    return transform_train, transform_val"
      ],
      "metadata": {
        "id": "TzyBv-Ebttd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = load_split(train_paths, df_class) # for normal training\n",
        "\n",
        "# df_train for undersampling / oversampling\n",
        "path_class = os.path.join(\"undersampled_rainforest.csv\")\n",
        "df_train = pd.read_csv(path_class)\n",
        "df_train[\"list_tags\"] = df_train.tags.str.split(\" \")\n",
        "\n",
        "df_val = load_split(val_paths, df_class)"
      ],
      "metadata": {
        "id": "yQzhLy7qtaIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train, transform_val = get_transforms()\n",
        "ds_train = AmazonDataset(df_train, transform_train, paths=train_paths)\n",
        "ds_val = AmazonDataset(df_val, transform_val, paths=val_paths)"
      ],
      "metadata": {
        "id": "OZr3-tYctdAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_class.head()  # displays the first 5 training data samples"
      ],
      "metadata": {
        "id": "UVbLzKAqn5wl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3d0a0ac-7aa4-492d-81a4-7523e3d2655a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  image_name                                       tags  \\\n",
              "0    train_0                               haze primary   \n",
              "1    train_1            agriculture clear primary water   \n",
              "2    train_2                              clear primary   \n",
              "3    train_3                              clear primary   \n",
              "4    train_4  agriculture clear habitation primary road   \n",
              "\n",
              "                                         list_tags  \n",
              "0                                  [haze, primary]  \n",
              "1             [agriculture, clear, primary, water]  \n",
              "2                                 [clear, primary]  \n",
              "3                                 [clear, primary]  \n",
              "4  [agriculture, clear, habitation, primary, road]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57072d2d-d581-47e5-8b58-9928209938dc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>tags</th>\n",
              "      <th>list_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>haze primary</td>\n",
              "      <td>[haze, primary]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>agriculture clear primary water</td>\n",
              "      <td>[agriculture, clear, primary, water]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>clear primary</td>\n",
              "      <td>[clear, primary]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>clear primary</td>\n",
              "      <td>[clear, primary]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>agriculture clear habitation primary road</td>\n",
              "      <td>[agriculture, clear, habitation, primary, road]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57072d2d-d581-47e5-8b58-9928209938dc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-57072d2d-d581-47e5-8b58-9928209938dc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-57072d2d-d581-47e5-8b58-9928209938dc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0792d39c-d9d5-439d-998b-7cd84222eae3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0792d39c-d9d5-439d-998b-7cd84222eae3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0792d39c-d9d5-439d-998b-7cd84222eae3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "Pswof8zV5PnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms as T, models\n",
        "import torch.nn as nn\n",
        "\n",
        "# MIGHT HAVE TO USE THIS COMMENTED VERSION IF YOUR PYTORCH DOESN'T WORK WITH THE PRETRAINED PARAMETER\n",
        "# def get_model(weights='DEFAULT', dropout_rate=0.2):\n",
        "  # model = models.resnet18(weights=weights)\n",
        "\n",
        "def get_model(pretrained=True, dropout_rate=0.2):\n",
        "    model = models.resnet18(pretrained=pretrained)\n",
        "    for param in model.parameters():\n",
        "        param.require_grad = False # freeze pretrained encoder\n",
        "    model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "    model.fc = nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(512, 128), # 512 for resnet18 or 2048 for resnet50\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Dropout(dropout_rate),\n",
        "      nn.Linear(128, 17),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    return model.to(device)"
      ],
      "metadata": {
        "id": "OOtgSAG2bX3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batch(X, Y, model, loss_fn, optimizer, loss_scale=1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    Y_hat = model(X)\n",
        "    batch_loss = 0\n",
        "\n",
        "    # scale loss for classes with fewer images\n",
        "    if loss_scale != 1:\n",
        "      loss_per_item = loss_fn(Y_hat, Y)\n",
        "      RARE_CLASSES = [ \"bare_ground\", \"selective_logging\", \"artisinal_mine\", \"blooming\", \"slash_burn\", \"blow_down\", \"conventional_mine\" ]\n",
        "      rare_classes_enc = torch.Tensor(transform_targets(RARE_CLASSES)).unsqueeze(0).to(device='cuda')\n",
        "      rare_classes_enc = torch.tile(rare_classes_enc, dims=(Y.shape[0],1))\n",
        "      mask = torch.tile((torch.sum(torch.logical_and(Y, rare_classes_enc), axis=1) > 0).unsqueeze(1), dims=(1,Y.shape[1]))\n",
        "      scaled_loss = torch.where(mask, loss_per_item * loss_scale, loss_per_item)\n",
        "      batch_loss = torch.mean(scaled_loss)\n",
        "    # don't scale loss\n",
        "    else:\n",
        "      batch_loss = loss_fn(Y_hat, Y)\n",
        "\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "    Y_hat = Y_hat.detach().float().cpu().numpy()  # detach predictions from gradients for logging\n",
        "\n",
        "    return Y_hat, batch_loss.item()"
      ],
      "metadata": {
        "id": "7_hLcbxZfjLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def compute_val_loss(X, Y, model, loss_fn):\n",
        "    model.eval()\n",
        "    Y_hat = model(X)\n",
        "    batch_loss = loss_fn(Y_hat, Y)\n",
        "    batch_loss = torch.mean(batch_loss)\n",
        "    Y_hat = Y_hat.float().cpu().numpy()\n",
        "\n",
        "    return Y_hat, batch_loss.item()"
      ],
      "metadata": {
        "id": "29sngwavfknP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import fbeta_score, confusion_matrix\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "def train_model(model, optimizer, loss_fn, dl_train, dl_val, epochs, filename, loss_scale):\n",
        "    lr_scheduler = StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "    loss_train, loss_val = [], []\n",
        "    score_train, score_val = [], []\n",
        "\n",
        "    Y_hat_val = None\n",
        "    best_loss_val = np.inf\n",
        "\n",
        "    for idx in range(epochs):\n",
        "        loss_train_epoch, loss_val_epoch = [], []\n",
        "        Y_hat_train_epoch, Y_hat_val_epoch = [], []\n",
        "        Y_train_epoch, Y_val_epoch = [], []\n",
        "\n",
        "        for X, Y in tqdm(dl_train, leave=False):\n",
        "            Y_hat, batch_loss = train_batch(X, Y, model, loss_fn, optimizer, loss_scale=loss_scale) # want to try 1.25, 1.5, 2, 2.5, 3?\n",
        "            loss_train_epoch.append(batch_loss)\n",
        "            Y_hat_train_epoch.extend(Y_hat)\n",
        "            Y_train_epoch.extend(Y.detach().float().cpu().numpy())\n",
        "\n",
        "        for X, Y in tqdm(dl_val, leave=False):\n",
        "            Y_hat, batch_loss = compute_val_loss(X, Y, model, loss_fn)\n",
        "            loss_val_epoch.append(batch_loss)\n",
        "            Y_hat_val_epoch.extend(Y_hat)\n",
        "            Y_val_epoch.extend(Y.detach().float().cpu().numpy())\n",
        "\n",
        "        avg_loss_train = np.mean(loss_train_epoch)\n",
        "        avg_loss_val = np.mean(loss_val_epoch)\n",
        "\n",
        "        Y_hat_train_epoch = np.array(Y_hat_train_epoch)\n",
        "        Y_hat_val_epoch = np.array(Y_hat_val_epoch)\n",
        "        Y_thresh_train_epoch = (Y_hat_train_epoch > .2).astype(float)\n",
        "        Y_thresh_val_epoch = (Y_hat_val_epoch > .2).astype(float)\n",
        "        Y_train_epoch = np.array(Y_train_epoch)\n",
        "        Y_val_epoch = np.array(Y_val_epoch)\n",
        "\n",
        "        score_train_epoch = fbeta_score(Y_train_epoch, Y_thresh_train_epoch, beta=2, average=\"samples\")\n",
        "        score_val_epoch = fbeta_score(Y_val_epoch, Y_thresh_val_epoch, beta=2, average=\"samples\")\n",
        "\n",
        "        # saving values for debugging\n",
        "        if avg_loss_val < best_loss_val:\n",
        "            best_loss_val = avg_loss_val\n",
        "            Y_hat_val = Y_hat_val_epoch\n",
        "            Y_thresh_val = Y_thresh_val_epoch\n",
        "            Y_val = Y_val_epoch\n",
        "\n",
        "        loss_train.append(avg_loss_train)\n",
        "        loss_val.append(avg_loss_val)\n",
        "        score_train.append(score_train_epoch)\n",
        "        score_val.append(score_val_epoch)\n",
        "\n",
        "        print(\n",
        "            f\"epoch: {idx}/{epochs} -- train loss: {avg_loss_train}, \" \\\n",
        "            f\"val loss: {avg_loss_val}\" \\\n",
        "            f\" -- train fbeta_score: {score_train_epoch}, \" \\\n",
        "            f\"val fbeta_score: {score_val_epoch}\"\n",
        "        )\n",
        "\n",
        "        # save checkpoint\n",
        "        torch.save(model, filename + f'{idx+1}.pt')\n",
        "        # pickle.dump(train_results, open(filename+'.results', \"wb\"))\n",
        "        print(f'Saved model to {filename}.pt')\n",
        "        # print(f'Saved results to {filename}.results')\n",
        "        # # if on Colab\n",
        "        # files.download(filename + f'{idx+1}.pt')\n",
        "\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    train_results = {\n",
        "        \"loss_train\": loss_train,\n",
        "        \"loss_val\": loss_val,\n",
        "        \"score_train\": score_train,\n",
        "        \"score_val\": score_val,\n",
        "        \"Y_hat_val\": Y_hat_val,\n",
        "        \"Y_thresh_val\": Y_thresh_val,\n",
        "        \"Y_val\": Y_val,\n",
        "    }\n",
        "\n",
        "    # torch.save(model, filename + '.pt')\n",
        "    pickle.dump(train_results, open(filename+'.results', \"wb\"))\n",
        "    # print(f'Saved model to {filename}.pt')\n",
        "    print(f'Saved results to {filename}.results')\n",
        "    # # if on Colab\n",
        "    # files.download(f'{filename}.results')"
      ],
      "metadata": {
        "id": "xStAEF84f8zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "# Set hyperparameters for batch size, epochs, learning rate\n",
        "BATCH_SIZE = 64\n",
        "LR = 1e-3\n",
        "EPOCHS = 20\n",
        "LOSS_SCALE = 1\n",
        "filename = 'model'\n",
        "\n",
        "# Load dataset in DataLoader\n",
        "dl_train = DataLoader(\n",
        "    ds_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=ds_train.collate_fn\n",
        ")\n",
        "dl_val = DataLoader(\n",
        "    ds_val,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    collate_fn=ds_val.collate_fn\n",
        ")\n",
        "\n",
        "# Initialize model\n",
        "model = get_model()\n",
        "optimizer = Adam(model.parameters(), lr=LR)\n",
        "loss_fn = nn.BCELoss(reduction='none') if LOSS_SCALE != 1 else nn.BCELoss()\n",
        "\n",
        "# load from checkpoint\n",
        "# model = torch.load('forest_clip_undersample_10.pt')\n",
        "\n",
        "# Checkpoint file to save models + results\n",
        "# Train\n",
        "train_model(\n",
        "    dl_train=dl_train,\n",
        "    dl_val=dl_val,\n",
        "    epochs=EPOCHS,\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    loss_fn=loss_fn,\n",
        "    filename=filename,\n",
        "    loss_scale=LOSS_SCALE\n",
        "    )"
      ],
      "metadata": {
        "id": "RYq_5eGzgCHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "zbUyOOhQdX3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(filename + '20.pt')  # load best model\n",
        "train_results = pickle.load(open(filename + '.results', \"rb\"))  # load best model results"
      ],
      "metadata": {
        "id": "EYHupnaB8g8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Track loss and performance over time (for train and val)\n",
        "loss_train = train_results[\"loss_train\"]\n",
        "loss_val = train_results[\"loss_val\"]\n",
        "score_train = train_results[\"score_train\"]\n",
        "score_val = train_results[\"score_val\"]\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Loss\", \"Fbeta scores\"))\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=list(range(len(loss_train))),\n",
        "        y=loss_train,\n",
        "        name=\"loss_train\",\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=list(range(len(loss_val))),\n",
        "        y=loss_val,\n",
        "        name=\"loss_val\",\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=list(range(len(score_train))),\n",
        "        y=score_train,\n",
        "        name=\"score_train\",\n",
        "    ),\n",
        "    row=1, col=2\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=list(range(len(score_val))),\n",
        "        y=score_val,\n",
        "        name=\"score_val\",\n",
        "    ),\n",
        "    row=1, col=2\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ye2Frz1MgWwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_hat_val = np.array(train_results[\"Y_hat_val\"])\n",
        "Y_val = np.array(train_results[\"Y_val\"])\n",
        "\n",
        "pos_probas, neg_probas = [], []\n",
        "for class_, idx in LABEL_IDXS.items():\n",
        "    pos_probas.append(Y_hat_val[np.where(Y_val[:, idx] != 0), idx].mean())\n",
        "    neg_probas.append(Y_hat_val[np.where(Y_val[:, idx] == 0), idx].mean())\n",
        "go.Figure([\n",
        "    go.Bar(x=list(LABEL_IDXS), y=pos_probas, name=\"Y_hat proba | Y = 1\"),\n",
        "    go.Bar(x=list(LABEL_IDXS), y=neg_probas, name=\"Y_hat proba | Y = 0\")\n",
        "]).show()"
      ],
      "metadata": {
        "id": "GEVm_up1MiNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_thresholds(Y_hat, Y):\n",
        "    \"\"\"\n",
        "    This is just a simple solution, but there are more rigorous ways to choose this threshold.\n",
        "    \"\"\"\n",
        "    N_tags = Y.shape[1]\n",
        "    best_threshs = [0.2] * N_tags\n",
        "    resolution = 100\n",
        "    for jdx in tqdm(range(N_tags)):\n",
        "        best_score = 0\n",
        "        threshs = best_threshs.copy()\n",
        "        for kdx in range(resolution):\n",
        "            kdx /= resolution\n",
        "            threshs[jdx] = kdx\n",
        "            Y_hat_thresh = (Y_hat > threshs).astype(float)\n",
        "            score = fbeta_score(Y, Y_hat_thresh, beta=2, average=\"samples\")\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_threshs[jdx] = kdx\n",
        "\n",
        "    global_best_score = fbeta_score(Y, (Y_hat > best_threshs).astype(float), beta=2, average=\"samples\")\n",
        "    print(f\"threshs: {best_threshs} -- best score: {global_best_score}\")\n",
        "\n",
        "    return best_threshs"
      ],
      "metadata": {
        "id": "nnCsnQS5MoVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshs = find_best_thresholds(Y_hat_val, Y_val)"
      ],
      "metadata": {
        "id": "LA8Hdf1BMpv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizes the confusion matrices\n",
        "fig = make_subplots(cols=4, rows=5, subplot_titles=list(LABEL_IDXS.keys()))\n",
        "for jdx in range(Y_val.shape[1]):\n",
        "    y_val = Y_val[:, jdx].ravel()\n",
        "    y_hat_val = (Y_hat_val[:, jdx].ravel() > threshs[jdx]).astype(float)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val, y_hat_val).ravel()\n",
        "    mat = np.array([[fn, tn], [tp, fp]])\n",
        "    ttl = np.sum(mat)\n",
        "    col = jdx % 4+1\n",
        "    row = jdx // 4+1\n",
        "    fig.add_trace(\n",
        "        go.Heatmap(\n",
        "            z=mat, text=[[f\"fn: {np.around(fn/ttl*100,2)}\", f\"tn: {np.around(tn/ttl*100,2)}\"], [f\"tp: {np.around(tp/ttl*100,2)}\", f\"fp: {np.around(fp/ttl*100,2)}\"]],\n",
        "            texttemplate=\"%{text}\", colorscale='Viridis', name=list(LABEL_IDXS.keys())[jdx],\n",
        "            hovertemplate=list(LABEL_IDXS.keys())[jdx],\n",
        "            showscale=False\n",
        "        ),\n",
        "        col=col, row=row,\n",
        "    )\n",
        "\n",
        "    fig.update_yaxes(showticklabels=False, row=row, col=col)\n",
        "    fig.update_xaxes(showticklabels=False, row=row, col=col)\n",
        "\n",
        "fig.update_layout(\n",
        "    width=1200, height=800, title=\"Confusion matrices\",\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "t4StF_ypM3Cs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}